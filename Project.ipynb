{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# supress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, ReLU, Dense, Flatten, Reshape, Input, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "from utility.preprocess import get_images_path, augment_test, augment_data, load_image_test, load_image_train, load_image_test_random, load_image_test_user_input\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in path 2\n",
    "\n",
    "fullDataset = True\n",
    "if fullDataset:\n",
    "    path1 = get_images_path(\"/dcs/large/u2146727/greyscale\")\n",
    "    path2 = get_images_path(\"/dcs/large/u2146727/colourcropped\")\n",
    "else:\n",
    "    path1 = get_images_path(\"/dcs/21/u2146727/cs310/dataset/edgecropped\")\n",
    "    path2 = get_images_path(\"/dcs/21/u2146727/cs310/dataset/colourcropped\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_Data = tf.data.Dataset.from_tensor_slices((path1, path2))\n",
    "\n",
    "#print all the images\n",
    "training_Data = training_Data.map(augment_data)\n",
    "training_Data = training_Data.batch(1)\n",
    "\n",
    "\n",
    "test1 = get_images_path(\"/dcs/21/u2146727/cs310/dataset/greyscale_test\")\n",
    "test2 = get_images_path(\"/dcs/21/u2146727/cs310/dataset/colourcropped_test\")\n",
    "test_Data = tf.data.Dataset.from_tensor_slices((test1, test2))\n",
    "test_Data = test_Data.map(augment_test).shuffle(100)\n",
    "test_Data = test_Data.batch(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hint_train_path = get_images_path(\"/dcs/large/u2146727/kaggle/data/train\")\n",
    "hint_train = tf.data.Dataset.from_tensor_slices(hint_train_path)\n",
    "hint_train = hint_train.map(lambda x: tf.py_function(load_image_train, [x], [tf.float32, tf.float32])).shuffle(100)\n",
    "hint_train = hint_train.batch(1)\n",
    "\n",
    "hint_test_path = get_images_path(\"/dcs/large/u2146727/kaggle/data/val_manual\")\n",
    "hint_test = tf.data.Dataset.from_tensor_slices(hint_test_path)\n",
    "hint_test = hint_test.map(lambda x: tf.py_function(load_image_test_user_input, [x], [tf.float32, tf.float32])).shuffle(100)\n",
    "hint_test = hint_test.batch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder block\n",
    "def encoder_block2(filters, size = 4, bn=True, activation='leakyrelu', batchsize=1):\n",
    "  initiailizer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
    "  encoder = tf.keras.Sequential([Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initiailizer, use_bias=False),] \n",
    "                                # batch normalisation should be higher in smaller batch sizes\n",
    "                                # and lower in larger batch sizes\n",
    "                                + ([BatchNormalization(momentum = 0.98)] if (bn and batchsize < 8) else [BatchNormalization(momentum = 0.9)] if (bn and batchsize >= 8) else [])\n",
    "                                + ([LeakyReLU(0.25)] if activation == 'leakyrelu' else [ReLU()] if activation == 'relu' else []))\n",
    "  return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder block\n",
    "def decoder_block2(filters, size = 4, dropout=False, activation='leakyrelu', batchsize=1):\n",
    "  initiailizer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
    "  result = tf.keras.Sequential([tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initiailizer, use_bias=False),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Dropout(0.5) if dropout else tf.keras.layers.Dropout(0.0),\n",
    "                               tf.keras.layers.LeakyReLU() if activation == 'leakyrelu' else tf.keras.layers.ReLU()])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
    "  filters = 64\n",
    "\n",
    "  input = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "  layer1 = encoder_block2(filters, bn=False)(input)\n",
    "\n",
    "  layer2 = encoder_block2(filters*2)(layer1)\n",
    "  layer3 = encoder_block2(filters*4)(layer2)\n",
    "  layer4 = encoder_block2(filters*8)(layer3)\n",
    "  layer5 = encoder_block2(filters*8)(layer4)\n",
    "  layer6 = encoder_block2(filters*8)(layer5)\n",
    "  layer7 = encoder_block2(filters*8)(layer6)\n",
    "  layer8 = encoder_block2(filters*8)(layer7)\n",
    "\n",
    "  up1 = decoder_block2(filters*8, dropout=True)(layer8)\n",
    "  up1 = tf.keras.layers.Concatenate()([up1, layer7])\n",
    "  up2 = decoder_block2(filters*8, dropout=True)(up1)\n",
    "  up2 = tf.keras.layers.Concatenate()([up2, layer6])\n",
    "  up3 = decoder_block2(filters*8)(up2)\n",
    "  up3 = tf.keras.layers.Concatenate()([up3, layer5])\n",
    "  up4 = decoder_block2(filters*8)(up3)\n",
    "  up4 = tf.keras.layers.Concatenate()([up4, layer4])\n",
    "  up5 = decoder_block2(filters*4)(up4)\n",
    "  up5 = tf.keras.layers.Concatenate()([up5, layer3])\n",
    "  up6 = decoder_block2(filters*2)(up5)\n",
    "  up6 = tf.keras.layers.Concatenate()([up6, layer2])\n",
    "  up7 = decoder_block2(filters)(up6)\n",
    "  up7 = tf.keras.layers.Concatenate()([up7, layer1])\n",
    "\n",
    "\n",
    "  tanhLayer = Conv2DTranspose(3, 4,strides=2,padding='same',kernel_initializer=initializer,activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "  output = tanhLayer(up7)\n",
    "\n",
    "  return tf.keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
    "  size = 64\n",
    "  label = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "  tar = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "  first_layer = tf.keras.layers.concatenate([label, tar]) \n",
    "\n",
    "  layer1 = encoder_block2(size, 4, False)(first_layer)\n",
    "  layer2 = encoder_block2(size*2, 4)(layer1) \n",
    "\n",
    "  padded1 = tf.keras.layers.ZeroPadding2D()(layer2)\n",
    "  encoder1 = Conv2D(512, 4, strides=1,kernel_initializer=initializer,use_bias=False)(padded1)\n",
    "  batchnorm1 = BatchNormalization()(encoder1)\n",
    "  leaky_relu1 = LeakyReLU()(batchnorm1)\n",
    "\n",
    "  padded2 = tf.keras.layers.ZeroPadding2D()(leaky_relu1)\n",
    "  encoder2 = Conv2D(512, 4, strides=1,kernel_initializer=initializer,use_bias=False)(padded2)\n",
    "  batchnorm2 = BatchNormalization()(encoder2)\n",
    "  leaky_relu2 = LeakyReLU()(batchnorm2)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu2) \n",
    "  sigmoid = Conv2D(1, 4, strides=1,kernel_initializer=initializer, activation='sigmoid')(zero_pad2)\n",
    "\n",
    "  return tf.keras.Model(inputs=[label, tar], outputs=sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def generator_loss(disc_generated_output, gen_output, target, lamb = 100, norm = \"l1\"):\n",
    "  lossmatrix_one = tf.ones(disc_generated_output.shape, dtype=tf.float32)\n",
    "  binaryCrossEntropy = tf.keras.losses.BinaryCrossentropy(label_smoothing=0) \n",
    "  gan_loss = binaryCrossEntropy(lossmatrix_one, disc_generated_output)\n",
    "  # Mean absolute error\n",
    "  if norm == \"l1\":\n",
    "    norm_loss = tf.reduce_mean(tf.abs(gen_output - target))\n",
    "  else:\n",
    "    # Mean squared error\n",
    "    norm_loss = tf.reduce_mean((target - gen_output)**2)\n",
    "  total_gen_loss = gan_loss + (lamb * norm_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, norm_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  lossmatrix_one = tf.ones(disc_real_output.shape, dtype=tf.float32)\n",
    "  lossmatrix_zero = tf.zeros(disc_generated_output.shape, dtype=tf.float32)\n",
    "  binaryCrossEntropy = tf.keras.losses.BinaryCrossentropy(label_smoothing=0)\n",
    "  real_loss = binaryCrossEntropy(lossmatrix_one, disc_real_output)\n",
    "  generated_loss = binaryCrossEntropy(lossmatrix_zero, disc_generated_output)\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colourise(model, test_input, tar):\n",
    "  prediction = model(test_input, training=True)\n",
    "  plt.figure(figsize=(30,30))\n",
    "  mse = 0\n",
    "  psnr = 0\n",
    "  ssim = 0\n",
    "\n",
    "  display_list = [test_input[0], tar[0], prediction[0]]\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    if i == 2:\n",
    "      img = (display_list[i] * 0.5 + 0.5) * 255\n",
    "      img = Image.fromarray(np.uint8(img))\n",
    "      # print mean absolute error\n",
    "      mse = tf.reduce_mean(tf.abs(display_list[i] - display_list[1]))\n",
    "      psnr = tf.image.psnr(tar[0], prediction[0], max_val=2.0)\n",
    "      ssim = tf.image.ssim(tar[0], prediction[0], max_val=2.0)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  return mse, psnr, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
    "@tf.function\n",
    "def train_step(input_image, target, step):\n",
    "  with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
    "    generated_colour_image = generator(input_image, training=True)\n",
    "    discriminator_real_image = discriminator([input_image, target], training=True)\n",
    "    discriminator_generated = discriminator([input_image, generated_colour_image], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(discriminator_generated, generated_colour_image, target)\n",
    "    disc_loss = discriminator_loss(discriminator_real_image, discriminator_generated)\n",
    "\n",
    "  generator_gradients = generator_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "  discriminator_gradients = discriminator_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, steps):\n",
    "  example_input, example_target = next(iter(test_ds.take(1)))\n",
    "\n",
    "  for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n",
    "    if (step) % 1000 == 0:\n",
    "      display.clear_output(wait=True)\n",
    "\n",
    "      colourise(generator, example_input, example_target)\n",
    "      print(f\"Step: {step//1000} thousand\")\n",
    "    train_step(input_image, target, step)\n",
    "    # Training step\n",
    "    if (step+1) % 10 == 0:\n",
    "      print('.', end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning loop here\n",
    "#fit(training_Data, test_Data, steps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greyscale_test = tf.data.Dataset.from_tensor_slices((test1, test2))\n",
    "greyscale_test = greyscale_test.map(augment_test).shuffle(100)\n",
    "greyscale_test = greyscale_test.batch(1)\n",
    "\n",
    "new_model = tf.keras.models.load_model('generator_greyscale.h5', compile=False)\n",
    "#get total, min and max pnsr\n",
    "for inp, tar in greyscale_test.take(len(greyscale_test)):\n",
    "    mse, psnr, ssim = colourise(new_model, inp, tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D of G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge1 = get_images_path(\"/dcs/21/u2146727/cs310/dataset/edgecropped\")\n",
    "edge_test = tf.data.Dataset.from_tensor_slices((edge1, test2))\n",
    "edge_test = edge_test.map(augment_test).shuffle(100)\n",
    "edge_test = edge_test.batch(1)\n",
    "\n",
    "new_model = tf.keras.models.load_model('generator_edges.h5', compile=False)\n",
    "for inp, tar in edge_test.take(len(edge_test)):\n",
    "    mse, psnr, ssim = colourise(new_model, inp, tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour Hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "hint_test_path = get_images_path(\"/dcs/21/u2146727/cs310/dataset/val_manual/\")\n",
    "hint_test = tf.data.Dataset.from_tensor_slices(hint_test_path)\n",
    "hint_test = hint_test.map(lambda x: tf.py_function(load_image_test_user_input, [x], [tf.float32, tf.float32])).shuffle(100)\n",
    "hint_test = hint_test.batch(1)\n",
    "\n",
    "new_model = tf.keras.models.load_model('generator-third.h5', compile = False)\n",
    "#get total, min and max pnsr\n",
    "for inp, tar in hint_test.take(len(hint_test)):\n",
    "    mse, psnr, ssim = colourise(new_model, inp, tar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
